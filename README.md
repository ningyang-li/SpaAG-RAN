**This article is my first work published on an SCI journal. To be honest, there must be some deficiencies in technical innovation and English writting. I will keep working hard in this field. Please feel free to comment if you find any problems. : )**

# SpaAG-RAN
**Spatial Attention Guided Residual Attention Network for Hyperspectral Image Classification** [Source](https://ieeexplore.ieee.org/abstract/document/9684915)  
Authors: Ningyang Li, Zhaohui Wang  
Journal: IEEE Access  
Environment: Python 3.6., Tensorflow 2.2.2, Keras 2.2.2, Numpy 1.19.  

**Abstract:**  
Hyperspectral image (HSI) classification has become a research hotspot. Recently, deep learning-based methods have achieved preferable performances by which the deep spectral-spatial features can be extracted from HSI cubes. However, in complex scenes, due to the diversity of the types of landcover and the bands in high dimensional, these methods are often hampered by the irrelevant spatial areas and the redundant bands, which results in the indistinguishable features and the restricted performance. In this article, a spatial attention guided residual attention network (SpaAG-RAN) is proposed for HSI
classification, which contains a spatial attention module (SpaAM), a spectral attention module (SpeAM), and a spectral-spatial feature extraction module (SSFEM). Based on the spectral similarity, the SpaAM is capable of capturing the relevant spatial areas composed of the pixels of the same category as the center pixel from HSI cube with a novel inverted-shifted-scaled sigmoid activation function. The SpeAM aims to select the bands which are beneficial to the spectral features representation. The SSFEM is exploited to extract the discriminating spectral-spatial features. To facilitate the processes of bands selection and features extraction, two well-designed spatial attention masks generated by the SpaAM are employed to guide the works of the SpeAM and the SSFEM, respectively. Moreover, a spatial consistency loss function is installed to maintain the consistency between the two spatial attention masks so that the network enables the distinction of the relevant features exactly. Experimental results on three HSI data sets show that the proposed SpaAG-RAN model can extract the discriminating spectral-spatial features and outperforms the state-of-the-arts.

**Contibutions:**  
1. A lightweight spectral-similarity-based SpaAM is designed to capture the relevant spatial areas, which describes the spatial distribution of homogeneous pixels and interfering pixels implicitly. In this module, the spectral similarities between the center pixel and its neighborhoods are measured by the efficient Euclidean distance. A novel inverted-shifted-scaled sigmoid activation function is then in charge of converting the similarities to the proper spatial weights.
2. To improve the classification performance, a spatial consistency loss function is conducted to enable the SSFEM to extract effective features by preserving the specificity of homogeneous pixels and interfering pixels.
3. An end-to-end SpaAG-RAN model, which incorporates the SpaAM, the SpeAM, and the SSFEM, is proposed to stress the relevant spatial areas and extract the discriminating spectral-spatial features for HSI classification.

![Image](https://github.com/ningyang-li/SpaAG-RAN/blob/9279f80c73960c0d18868e78543bd95b3fc7efae/pic/overview.jpg)

**Citation:**  
N. Li and Z. Wang, "Spatial Attention Guided Residual Attention Network for Hyperspectral Image Classification," IEEE Access, vol. 10, pp. 9830-9847, 2022, doi: 10.1109/ACCESS.2022.3144393.

<code>@ARTICLE{9684915,
  author={Li, Ningyang and Wang, Zhaohui},
  journal={IEEE Access}, 
  title={Spatial Attention Guided Residual Attention Network for Hyperspectral Image Classification}, 
  year={2022},
  volume={10},
  number={},
  pages={9830-9847},
  keywords={Feature extraction;Hyperspectral imaging;Correlation;Convolutional neural networks;Training;Data mining;Computational modeling;Hyperspectral image classification;attention mechanism;deep learning;spatial attention;residual network},
  doi={10.1109/ACCESS.2022.3144393}}
</code>

